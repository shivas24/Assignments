{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0q721yaEgGBS3QJaj2kQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivas24/Assignments/blob/main/audio_video_text_converter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgj7V-kfD8r6",
        "outputId": "e5f06f75-52e5-4c19-dfe9-0e1a9b5638de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
            "Enter directory address::\n",
            "/content\n",
            "MoviePy - Writing audio in /content/videoplayback.mp4.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio extracted successfully from Video Fles:: videoplayback.mp4.mp3\n",
            "Total Audio Files extracted:: 1\n",
            "\n",
            "\n",
            "Audio converted to text successfully:: videoplayback.mp4.mp3.txt\n",
            "Audio converted to text successfully:: Speaker0039_004.wav.txt\n",
            "Audio converted to text successfully:: Speaker26_000.wav.txt\n",
            "Audio converted to text successfully:: Speaker26_001.wav.txt\n",
            "Audio converted to text successfully:: Speaker30_000.wav.txt\n",
            "Audio converted to text successfully:: videoplayback.mp4.mp3.txt\n",
            "Audio Files::: (0, '/content/videoplayback.mp4.mp3')\n",
            "Audio Files::: (1, '/content/sample_data/Speaker0039_004.wav')\n",
            "Audio Files::: (2, '/content/sample_data/Speaker26_000.wav')\n",
            "Audio Files::: (3, '/content/sample_data/Speaker26_001.wav')\n",
            "Audio Files::: (4, '/content/sample_data/Speaker30_000.wav')\n",
            "Audio Files::: (5, '/content/videoplayback.mp4.mp3')\n",
            "\n",
            "\n",
            "Video Files::: (0, '/content/sample_data/videoplayback.mp4')\n"
          ]
        }
      ],
      "source": [
        "#installs necessary moduels\n",
        "\n",
        "!pip install openai-whisper # to convert audio to text\n",
        "!pip install moviepy   # to convert video to audio\n",
        "\n",
        "#imports necessary libraries\n",
        "import os\n",
        "import whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "import warnings\n",
        "\n",
        "try:  # to catch errors we used try block\n",
        "    warnings.filterwarnings(\"ignore\")  # tohandle errors and ignres\n",
        "    directory_path=input(\"Enter directory address::\\n\") #We ask manually to tenter directory path to search audio video files\n",
        "    # print(directory_path,os.getcwd())\n",
        "\n",
        "# function to convert video audio files to text\n",
        "    def video_audio_files(directory_path):     # giving input what we have asked , the source directory\n",
        "        audio_formats={\".mp3\",\".wav\",\".m4a\",\".wma\"}   # to declare required audio extensions\n",
        "        video_formats={\".mpeg\", \"mpeg4\",\".mp4\",\".mov\",\".avi\"} # to declare required video extensions\n",
        "        audio_files=[]    #collects all audio files in the directory to this list\n",
        "        video_files=[]    # collects all video files in the directory to this list\n",
        "\n",
        "\n",
        "        if os.path.exists(directory_path): # checks if file exists\n",
        "\n",
        "            for root,items,files in os.walk(directory_path):\n",
        "                # os.walk returns as  generator with 3 tuples root,folder,files\n",
        "                # for loop to be used here to iterate all folder , subfolders and files in the directory path\n",
        "                for item in files: #iterates all files to check audio, video formats given\n",
        "\n",
        "                    if item.lower().endswith(tuple(audio_formats)):  #if a file ends with given audio format\n",
        "                        audio_files.append(os.path.join(root,item))  # appends to the list names audio_files\n",
        "\n",
        "                    elif item.lower().endswith(tuple(video_formats)): #else check if a file ends with given video formats\n",
        "                        video_files.append(os.path.join(root,item))  # appends to given video_files list\n",
        "\n",
        "        return audio_files, video_files   # returns the 2 lists of audio_files and video_files\n",
        "# To extract  audio from video. here we are using moviepy the easier one\n",
        "    def extract_audio_from_video(video_files):   # give video_files  as a list data type\n",
        "\n",
        "        count=0         # to count total files extracted of video formats\n",
        "        for item in video_files:    #iterates each video file\n",
        "            clip=VideoFileClip(item)   # loads the video into clip variable\n",
        "            mp3_file_path=os.path.join(directory_path,f\"{os.path.basename(item)}.mp3\")\n",
        "            # here we are joining source path of this file with its original name to convert to audio format mp3\n",
        "            clip.audio.write_audiofile(mp3_file_path)  #  seperates the given video file to mp3 audio format file\n",
        "\n",
        "            print(\"Audio extracted successfully from Video Fles::\",f\"{os.path.basename(item)}.mp3\") # prints the successful confoirmaiton message\n",
        "            clip.close()  # closes the clip variable\n",
        "            audio_files.append(mp3_file_path) # this extrcated mp3 audio file from the video has been appending to audio_files list data type for further convert to text\n",
        "            count+=1     # increments count value\n",
        "        print(\"Total Audio Files extracted::\",count)  # prints total numbers of audio files extracted and stored to audio_files lis data type from the source video files\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    def convert_audio_to_text(audio_files,directory_path):  # fundtion to convert audio to text\n",
        "\n",
        "        model = whisper.load_model(\"tiny\")  # Here we are using tiny model, which takes less file size, we can use base, turbo and other models\n",
        "\n",
        "        for item in audio_files:   #to iterate each audio file  in the list\n",
        "            output_folder=os.path.join(directory_path,\"output\")  # creates outputfolder with a folder name \"output\" in the given directory path\n",
        "            os.makedirs(output_folder,exist_ok=True)   # if directory exists leaves else create a folder\n",
        "\n",
        "            with open(os.path.join(output_folder,f\"{os.path.basename(item)}.txt\"),\"w\") as file:\n",
        "                # we are creating a file with its original basename by giving an extension because we are converting to text format\n",
        "                result = model.transcribe(item)  # here model transcribes the audio file to text and and stores the in result varibale\n",
        "                file.write(result[\"text\"])  # write the extracted text to file\n",
        "                print(\"Audio converted to text successfully::\",f\"{os.path.basename(item)}.txt\")  # prints succeessful message after writing into file and the file name\n",
        "                file.close() # closes the file\n",
        "\n",
        "# calling each function\n",
        "\n",
        "    audio_files,video_files=video_audio_files(directory_path)\n",
        "    extract_audio_from_video(video_files)\n",
        "    convert_audio_to_text(audio_files,directory_path)\n",
        "\n",
        "# prints each file\n",
        "    [print(\"Audio Files:::\",(i)) for i in enumerate(audio_files)]\n",
        "    print(\"\\n\")\n",
        "    [print(\"Video Files:::\",(i)) for i in enumerate(video_files)]\n",
        "\n",
        "# To catch errors and we used here try except else  else system generating lot of warnings.\n",
        "except Exception as e:\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "else:\n",
        "    pass\n",
        "finally:\n",
        "    pass"
      ]
    }
  ]
}